- [第1章 什么是高并发](#第1章-什么是高并发)
  - [1.2 高并发系统有哪些关键指标](#12-高并发系统有哪些关键指标)
    - [1.2.1 响应时间](#121-响应时间)
    - [1.2.2 吞吐量](#122-吞吐量)
    - [1.2.3 QPS（每秒请求数）](#123-qps每秒请求数)
    - [1.4.2 高并发系统之分布式架构](#142-高并发系统之分布式架构)
    - [1.4.3 高并发系统之微服务架构](#143-高并发系统之微服务架构)
- [第2章 从剖析两个高并发系统开始](#第2章-从剖析两个高并发系统开始)
  - [2.1 案例一：千万级流量“秒杀”系统](#21-案例一千万级流量秒杀系统)
    - [2.1.1 架构一览](#211-架构一览)
    - [2.1.2 动静分离方案设计](#212-动静分离方案设计)
  - [2.2 案例二：C2C二手电商平台的社会化治理系统](#22-案例二c2c二手电商平台的社会化治理系统)
    - [3 分布式事务](#3-分布式事务)
      - [(1) XA二阶段提交](#1-xa二阶段提交)
- [第3章 生产级系统框架设计的细节](#第3章-生产级系统框架设计的细节)
  - [3.1.2 如何避免重复提交](#312-如何避免重复提交)
    - [1 全局唯一ID防止重复提交](#1-全局唯一id防止重复提交)
    - [2 使用"Token + Redis"机制防止重复提交](#2-使用token--redis机制防止重复提交)
    - [3.1.3 如何避免更新中的ABA问题](#313-如何避免更新中的aba问题)
- [第6章 应用集群化](#第6章-应用集群化)
  - [6.1 集群分类](#61-集群分类)
  - [6.1.3 集群系统和分布式系统区别](#613-集群系统和分布式系统区别)
  - [6.2 Nginx为作负载均衡器搭建集群](#62-nginx为作负载均衡器搭建集群)
- [第7章 缓存设计](#第7章-缓存设计)
  - [7.1 多级缓存](#71-多级缓存)
    - [7.1.1 HTTP缓存](#711-http缓存)
  - [7.4.3 缓存雪崩](#743-缓存雪崩)
  - [7.4.4 缓存穿透](#744-缓存穿透)
- [第8章 存储系统设计](#第8章-存储系统设计)
  - [8.2 Mysql主从架构](#82-mysql主从架构)
  - [8.3 数据库读写分离](#83-数据库读写分离)
- [第10章 消息中间件设计](#第10章-消息中间件设计)
  - [10.2.2 生产级消息中间件选型](#1022-生产级消息中间件选型)
- [第14章 【项目实战】搭建千万级流量”秒杀“系统](#第14章-项目实战搭建千万级流量秒杀系统)
  - [14.1.1 技术选型标准](#1411-技术选型标准)
  - [14.2.3 高可用指标](#1423-高可用指标)


[toc]





# 第1章 什么是高并发

## 1.2 高并发系统有哪些关键指标

### 1.2.1 响应时间

发出请求到收到系统完整响应数据所需的时间。

<br />

### 1.2.2 吞吐量

单位时间内系统处理的用户请求数。不同的上下文，有不同的定义。

从业务角度看，吞吐量可以用“请求数/秒”，“人数/天”，或“处理业务数/小时” 等来衡量。

从网络角度看，可以用“字节数/秒”来衡量。

<br />

### 1.2.3 QPS（每秒请求数）

预估QPS的方法：绝大部分系统在白天的请求量都比较大，所以以白天来计算QPS。依据二八原则，80%的流量是在20%的时间段内产生的。

例如，每天有5 000 000个请求，预估QPS = ( 5 000 000 * 0.8）/ （12 * 60 * 60 * 0.2）= 462 。即当前系统每天平均QPS为462，为保险起见，再预留个20%左右。

80%的流量在白天进行，所以乘以0.8。

白天12个小时，在这12个小时里有效时间为0.2，转换秒。

再得出峰值QPS，一般为平均QPS的两倍。即，峰值QPS = 2 * 平均QPS。

所有，需要部署的机器数 = 峰值QPS / 单台机器最高可承受的QPS（实际跑压测出来）。

<br />

### 1.4.2 高并发系统之分布式架构

分布式架构就是将一个系统拆分为多个独立的应用，各应用相互协作，组成一个整体，共同完成任务。

<br />

### 1.4.3 高并发系统之微服务架构

因为分之布架构的局限，所有才演进出了微服务架构。

微服务架构的问题：

1. 增加了复杂度。服务数量增加、交互模式的变更；
2. 服务边界划分是困难，不能过粗过细，需要很强的业务沉淀；
3. 保持数据一致性复杂；
4. 需要更强的运维知识；
5. 增加了开发流程的复杂性；

在微服务架构中，所有的服务都是独立部署的。当服务数量很大时，如果还是像单体应用那样进行人工部署，则效率会非常低。所以微服务架构必须要通过自动化的方式来部署。现在，持续集成及持续部署都是通用的实践了。

<br />



# 第2章 从剖析两个高并发系统开始

## 2.1 案例一：千万级流量“秒杀”系统

### 2.1.1 架构一览

```js
         --------------------------------------------------
         |   --------        -------       ------         |
 用户层   |  |   App  |      |  H5   |     |  PC  |        |  
         |   --------        --------      ------         |
         --------------------------------------------------
               
         --------------------------------------------------
         |   --------        -------       ------         |
 CDN层    |  |  CDN1 |      |  CDN2 |     | CDN3 |        |   缓存秒杀活动的静态资源文件
         |   --------        --------      ------         |
         --------------------------------------------------
         
         --------------------------------------------------
         |   --------        -------       ------         |
 SLB层    |  |  SLB1  |      |  SLB2 |     | SLB3 |       |    分发请求
         |   --------        --------      ------         |
         --------------------------------------------------
      
         --------------------------------------------------
         |   --------------        ----------              |
 服务层   |  |  秒杀交易系统  |      |  等等系统 |             |
         |   --------------        -----------             |
         --------------------------------------------------
         
         --------------------------------------------------
         |   --------        -------------      --------   |
 基础设施层|  |  数据库  |     |  消息中间件  |     | 大数据 |  |
         |   --------        -------------      --------   |
         --------------------------------------------------
         
```

### 2.1.2 动静分离方案设计

什么是静态数据：

* HTML、CSS、JS文件；
* 图片等；

可以通过代理服务器缓存静态数据，例如：浏览器本地缓存（包括App端、PC端）、CDN、Nginx、Squid、Varnish等。一级一级的缓存。

```js
         -----------------------------------
         |   --------        -------       |
         |  |   App  |      |  PC   |      |  
         |   --------        -------       |
         -----------------------------------
            ⬇️                 ⬇️
         -----------------------------------
         |   --------        -------       |
         |  |   CDN1  |      | CDN2 |      |  
         |   --------        -------       |
         -----------------------------------
            ⬇️                  ⬇️
         -----------------------------------
         |   --------        -------       |
         |  | Nginx  |      | Squid |      |  
         |   --------        -------       |
         -----------------------------------
```

<br />

页面静态化：直接缓存HTTP连接，而不是缓存数据。如，代理服务器根据请求的URL直接返回HTTP对应的响应头及响应消息体。

```js
                          -------------------
                          |    代理服务器     |
用户 ---->  URL请求  ----> |    HTTP Head     |   ---> 后端服务器  ---> DB
                          |    HTTP Body     |
                          --------------------
```

<br />

## 2.2 案例二：C2C二手电商平台的社会化治理系统

Nacos做服务注册中心。

### 3 分布式事务

目前实现分布式事务的解决方案有如下几种：

* 基于XA协议的二阶段提交； 强一致性
* 基于XA协议的三阶段提交； 强一致性
* TCC；
* 基于消息的最终一致性（BASE理念）

<br />

#### (1) XA二阶段提交

分准备阶段、提交阶段。引入事务协调者，通过它来保证各个事务被正确提交。

第一阶段，准备阶段，协调者向所有参与者发送准备指令，等待回复。参与者收到“准备”指令后，就各自进行自己的业务处理，成功则返回“准备成功”，失败则返回“准备失败”。

第二阶段，提交阶段，协调者依据各参与者的返回消息，如果都是成功，则发送”提交“指令，否则则发送”回滚“指令。



# 第3章 生产级系统框架设计的细节 

## 3.1.2 如何避免重复提交

### 1 全局唯一ID防止重复提交

1. 搭建一个全局唯一ID的服务，可以用SnowFlake；
2. 在订单确定下单页面，调用全局ID服务生成订单号；
3. 提交订单时带上订单号，请求到达订单系统，利用数据库的唯一约束；

<br />

### 2 使用"Token + Redis"机制防止重复提交

1. 订单系统提供一个发放Token的接口，同时写入Redis；

2. 在”订单确认页“中调用获取Token的接口；

3. 用户在”订单确认页“提交订单时，带上Token，给服务端校验，如果Redis有Token，是第一个请求，如果没有，则是重复请求；

   <br />

### 3.1.3 如何避免更新中的ABA问题

前端每次传数据，都要带上version，后端服务每次update时都带上version判断即可。

<br />



# 第6章 应用集群化

## 6.1 集群分类

```js
              -----> 高可用集群
              |
集群服务器分为: |              
              |               | -----> 负载均衡集群 一般都是这种，各个web服务组成一块构成
              -----> 高性能集群 | -----> 计算集群
                              | -----> 存储集群

```

<br />

## 6.1.3 集群系统和分布式系统区别

集群系统：同一个业务部署在多个服务器上，同时对外服务。

分布式：同一个业务被拆成多个子业务，分别部署到不同的机器上，这些子业务协作完成一件事件。

<br />

## 6.2 Nginx为作负载均衡器搭建集群

```js
                      -----------            --------------
                      |         |            | webServer1 |
----------            |         |            --------------
|  客户端 |   ------>  |         |  ----->
----------            |         |
                      |  nginx  |
                      |         |
----------            |         |            ---------------
|  客户端 |   ------>  |         |  ----->    | webServer2  |  
----------            |         |            ---------------
                      -----------
```

nginx负载均衡算法分类：

* Round-Robin或Least-Connected，属于无状态水平扩展；
* 基于URL分发。将不同功能的URL分发到不同的节点；
* 基于用户信息，如IP地址或者用户名等；



# 第7章 缓存设计

## 7.1 多级缓存

```js
--------
|用户请求| ---> 客户端缓存 ---> CDN缓存 ---> 反向代理缓存 ---> 远程缓存(redis) ---> 应用缓存 --> DB
--------          |
              ---------
              |       |
           HTTP缓存  浏览器缓存
```

<br />

### 7.1.1 HTTP缓存

两种模式：强制缓存、协商缓存。

**强制缓存**：版本处理不同，HTTP1.0下由Expires头控制：

```js
---------                                      ---------
| 浏览器 |                                      | 服务器 |
---------                                      ---------
    |      1. 请求a.png                            |
    |      -------------------------------->       |
    |                                              |
    |      2. 返回a.png, 设置头Expires               |
    |      <-------------------------------        |
    |                                              |
    |      3. 再次请求a.png时, 浏览器判断Expires:      |
    |         过期: 发请求                           |
    |         不过期: 不发请求, 直接用缓存              |
    |  (这里跟书上讲的不同，书上讲的是由服务器对比，但查资料是浏览器对比的)
    |      ------------------------------->         |
    |                                               |
      
```

由于浏览器时间与服务器不一致, 所有不准确，被1.1取代。

HTTP1.1由Cache-Control头控制：

```js
Cache-Control: max-age=60 // 数据被缓存后, 在60s内请求都会从缓冲取, 不请求服务器
请求过程和Expires一样。
```

<br />

**协商缓存**：每次读取数据时都需要和服务器通信，来决定是否更新缓存。也分为HTTP1.0和HTTP1.1。

HTTP1.0用Last-Modified头控制：

```js
---------                                      ---------
| 浏览器 |                                      | 服务器 |
---------                                      ---------
    |    1. 请求a.png                            |
    |    -------------------------------->       |
    |                                            |
    |    2. 返回a.png, 设置头Last-Modified         | // 最后修改时间
    |    <-------------------------------        |
    |                                            |
    |    3. 再次请求a.png时, 带上If-Modified-Since  |
    |     ------------------------------->        |
    |                                             |
    |    4. 服务器判断a.png的Last-Modified > If-M-S: |
    |       有更新返回资源200;                       |
    |       没更新返回304, 浏览器从缓存取;             |
    |      <-------------------------------        |
    |                                              |
```

<br />

HTTP1.1由ETag头控制：

```js
---------                                      ---------
| 浏览器 |                                      | 服务器 |
---------                                      ---------
    |    1. 请求a.png                            |
    |    -------------------------------->       |
    |                                            |
    |    2. 返回a.png, 设置头ETag                  | // a.png hash值
    |    <-------------------------------        |
    |                                            |
    |    3. 再次请求a.png时, 带上If-None-Match     |
    |     ------------------------------->       |
    |                                            |
    |    4. 服务器判断a.png的Hash === If-N-M:      |
    |       有更新返回资源200;                     |
    |       没更新返回304, 浏览器从缓存取;           |
    |      <-------------------------------      |
    |                                            |
```

## 7.4.3 缓存雪崩

雪崩：是指部分缓存节点不可用，从此导致整个缓存系统不可用。分两种情况：

* 缓存不支持rehash，缓冲节点挂了，请求穿透到DB，导致DB挂了；
* 缓存支持rehash，瞬时流量落到一两个缓存节点导致这两个节点挂了，扩散到其他节点挂了；

（跟之前网上看的雪崩概念不一样，雪崩是大批缓存失效，流量全都打到DB，解决方案是设置不同的过期时间）

解决方案：

* 对DB访问增加限流。监控发现DB请求变慢时，不给读；
* 给缓存系统节点增加多个副本；



## 7.4.4 缓存穿透

穿透：访问的key不在缓存中，穿透到DB查也没有这个值，大量恶意访问不存在的值，拖垮DB。

解决方案：

* 设置个空的值，给一个很短的过期时间；
* 布隆过滤器；





# 第8章 存储系统设计

## 8.2 Mysql主从架构

主从复制，一主多从。Mysql可以配置强一致的同步复制，但生产项目中都不用，因为性能太差了。一般都是异步复制。



## 8.3 数据库读写分离

```js
                    --------
                   |  客户端 |         
              写    --------        读请求
            <-------|      |---------------> -------      ---------
  --------              同步                 | Slave1 |   | Slave2 |
 | Master |      ----------------->          -------      ---------
  --------
```

读写分离数据不一致怎么办？

* 没有绝对的技术手段可以解决。通常是在产品端采用中和的方案来解决。比如在订单支付场景下，在支付成功后不是直接跳转到订单页，而是跳转到一个”支付成功“的页面，留出时间让数据同步。

代码里读写分离如何区分读写库？

* 硬编码；
* 集成第三方组件，如Sharding-JDBC；
* 数据库中间件，如Mycat、Atlas、DBproxy；



# 第10章 消息中间件设计

走马观花，没什么深印象。要加强一个消息中间件的使用、还有keepalived。

## 10.2.2 生产级消息中间件选型

业界使用较多的消息中间件有3个：Kafka、RabbitMQ和RocketMQ。

1、Kafka优点：

* 高吞吐量。在4 CPU + 8 GB内存下，一台机器可以有十几万的QPS；利益于顺序写磁盘和零拷贝。
* 性能较高。发送消息在”毫秒“级别；
* 支持集群。部分机器宕机不影响集群正常使用；

 缺点：

* 有可能丢失数据。因为它收到消息后并不是直接写入物理磁盘，而是先写入磁盘缓冲区；

一般用Kafka来收集日志，丢了也不可惜。

<br />

2、RabbitMQ优点：

* 能保证不丢失数据；
* 支持集群；
* 支持很多高级功能，如消息重试、死信队列等；

缺点：

* 吞吐量较低。对于大型电商平台的”秒杀“活动，不能胜任；

如果公司业务比较平稳，就选择RabbitMQ。

<br />

3、RocketMQ优点：

* 吞吐量高，普通机器可以达到十万QPS；
* 集群、数据不丢失；
* 支持各种高级功能，如延迟消息、消息回溯等；

经常搞一些特大的”秒杀“活动，就选Rocket。







# 第14章 【项目实战】搭建千万级流量”秒杀“系统

## 14.1.1 技术选型标准

* 简单：逻辑和架构应该尽可能简单；
* 易用：上手容易、文档丰富、社区活跃；
* 易扩展：
* 稳定：问题少；
* 低成本：

## 14.2.3 高可用指标

* MTBF（Mean Time Between Failure）平均可用时长。一段时间系统正常稳定运行的平均时长。如3天内出现了3次故障，每次持续1个小时，那这3天的MTBF =  (3  * 24 - 3)  / 3 = 23小时。

* MTTR（Mean Time To Repair）平均修复时长。系统从失效到恢复正常所消耗的平均时长。

* SLA（Service-Level Agreement）服务等级协议。用来评估服务可用性等级，

  计算公式 = MTFB / (MTFB + MTTR)。一般说的可用性高于99.99%，就是指SLA。
- [第1章 什么是高并发](#第1章-什么是高并发)
  - [1.2 高并发系统有哪些关键指标](#12-高并发系统有哪些关键指标)
    - [1.2.1 响应时间](#121-响应时间)
    - [1.2.2 吞吐量](#122-吞吐量)
    - [1.2.3 QPS（每秒请求数）](#123-qps每秒请求数)
    - [1.4.2 高并发系统之分布式架构](#142-高并发系统之分布式架构)
    - [1.4.3 高并发系统之微服务架构](#143-高并发系统之微服务架构)
- [第2章 从剖析两个高并发系统开始](#第2章-从剖析两个高并发系统开始)
  - [2.1 案例一：千万级流量“秒杀”系统](#21-案例一千万级流量秒杀系统)
    - [2.1.1 架构一览](#211-架构一览)
    - [2.1.2 动静分离方案设计](#212-动静分离方案设计)
  - [2.2 案例二：C2C二手电商平台的社会化治理系统](#22-案例二c2c二手电商平台的社会化治理系统)
    - [3 分布式事务](#3-分布式事务)
      - [(1) XA二阶段提交](#1-xa二阶段提交)
- [第3章 生产级系统框架设计的细节](#第3章-生产级系统框架设计的细节)
  - [3.1.2 如何避免重复提交](#312-如何避免重复提交)
    - [1 全局唯一ID防止重复提交](#1-全局唯一id防止重复提交)
    - [2 使用"Token + Redis"机制防止重复提交](#2-使用token--redis机制防止重复提交)
    - [3.1.3 如何避免更新中的ABA问题](#313-如何避免更新中的aba问题)
- [第6章 应用集群化](#第6章-应用集群化)
  - [6.1 集群分类](#61-集群分类)
  - [6.1.3 集群系统和分布式系统区别](#613-集群系统和分布式系统区别)
  - [6.2 Nginx为作负载均衡器搭建集群](#62-nginx为作负载均衡器搭建集群)
- [第7章 缓存设计](#第7章-缓存设计)
  - [7.1 多级缓存](#71-多级缓存)
    - [7.1.1 HTTP缓存](#711-http缓存)
  - [7.4.3 缓存雪崩](#743-缓存雪崩)
  - [7.4.4 缓存穿透](#744-缓存穿透)
- [第8章 存储系统设计](#第8章-存储系统设计)
  - [8.2 Mysql主从架构](#82-mysql主从架构)
  - [8.3 数据库读写分离](#83-数据库读写分离)
- [第10章 消息中间件设计](#第10章-消息中间件设计)
  - [10.2.2 生产级消息中间件选型](#1022-生产级消息中间件选型)
- [第14章 【项目实战】搭建千万级流量”秒杀“系统](#第14章-项目实战搭建千万级流量秒杀系统)
  - [14.1.1 技术选型标准](#1411-技术选型标准)
  - [14.2.3 高可用指标](#1423-高可用指标)

